{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "311dc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f77a9-ff23-41cc-bc49-09e5da8a0f7f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5266651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in manually coded data for 2022 and 2020\n",
    "df = pd.read_csv('data/fbel_prepared_2022.csv', encoding = 'UTF-8')\n",
    "df20 = pd.read_csv('data/fbel_prepared.csv', encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74eb2f24-663f-45f1-971a-1f4788353f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "667a3e34-33b4-40ce-a0a4-63a71caf3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent data leakage, make sure the same features don't go into both train and test \n",
    "df = df.drop_duplicates(subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf5aaf92-b5a1-44cd-a382-bfd9ea7b4a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMARY_PERSUADE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       460\n",
      "           1       0.87      0.93      0.90       872\n",
      "\n",
      "    accuracy                           0.86      1332\n",
      "   macro avg       0.86      0.84      0.85      1332\n",
      "weighted avg       0.86      0.86      0.86      1332\n",
      "\n",
      "DONATE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99      1029\n",
      "         1.0       0.97      0.93      0.95       245\n",
      "\n",
      "    accuracy                           0.98      1274\n",
      "   macro avg       0.98      0.96      0.97      1274\n",
      "weighted avg       0.98      0.98      0.98      1274\n",
      "\n",
      "GOTV\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.96      0.94      1033\n",
      "         1.0       0.78      0.63      0.70       241\n",
      "\n",
      "    accuracy                           0.90      1274\n",
      "   macro avg       0.85      0.80      0.82      1274\n",
      "weighted avg       0.89      0.90      0.89      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "models = {}\n",
    "\n",
    "results_dir = 'performance'\n",
    "\n",
    "clf_rf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('cal', CalibratedClassifierCV(RandomForestClassifier(n_estimators=500, random_state=123), cv=5, method=\"sigmoid\"),)\n",
    "])\n",
    "\n",
    "model_name = 'rf'\n",
    "\n",
    "# Other rare categories: \"EVENT\", \"POLL\", \"GATHERINFO\", \"LEARNMORE\", \"CONTACT\", \"PURCHASE\"\n",
    "goals = [\"PRIMARY_PERSUADE\", \"DONATE\", \"GOTV\"]\n",
    "\n",
    "for g in goals:\n",
    "  \n",
    "  print(g)\n",
    "  \n",
    "  curr_df = df[['text', g]].dropna(subset=[g])\n",
    "\n",
    "  X_train, X_test, y_train, y_test = ms.train_test_split(curr_df['text'], curr_df[g], test_size=0.2, random_state=123)\n",
    "  \n",
    "  clf_rf.fit(X_train, y_train)\n",
    "  y_preds = clf_rf.predict(X_test)\n",
    " \n",
    "  \n",
    "  print(metrics.classification_report(y_test, y_preds))\n",
    "  \n",
    "#   df_perf = pd.DataFrame(metrics.precision_recall_fscore_support(test[g], predicted))\n",
    "#   df_perf.index = ['Precision', 'Recall', 'F-Score', 'Support']\n",
    "#   df_perf.to_csv(results_dir + \"/\" + model_name + \"/\" + g + '.csv')\n",
    "\n",
    "  # Save model to disk\n",
    "  # dump(clf_rf, f'models/goal_rf_{g}_2020_2022.joblib')\n",
    "    \n",
    "  # Save model on the go\n",
    "  models[g] = clf_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ffef0-f5c0-45df-b46a-9dbbf329a9de",
   "metadata": {},
   "source": [
    "## Inference: Meta 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4a44172-4c1f-4c01-9d7d-f79ef876cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "path_fb22_acb = 'data/fb2022_prepared.csv.gz'\n",
    "# dir_models = 'models/goal_rf_'\n",
    "# Ouput data\n",
    "path_predictions_gz = 'data/ad_goal_rf_fb2022.csv.gz'\n",
    "\n",
    "# Load data\n",
    "inference = pd.read_csv(path_fb22_acb)\n",
    "inference = inference[inference['text'] != \"\"]\n",
    "inference = inference.dropna(subset='text')\n",
    "\n",
    "goals = [\"PRIMARY_PERSUADE\", \"DONATE\", \"GOTV\"]\n",
    "\n",
    "for g in goals:\n",
    "\n",
    "  # Load model\n",
    "  clf = models[g]\n",
    "  # Load saved model\n",
    "  # clf = load(dir_models + g + '.joblib')\n",
    "  \n",
    "  # Apply clf\n",
    "  predicted_prob = clf.predict_proba(inference['text'])\n",
    "  predicted = np.argmax(predicted_prob, axis=1)\n",
    "  \n",
    "  inference['goal_'+g+'_prediction'] = predicted\n",
    "  inference['goal_'+g+'_predicted_prob'] = predicted_prob[:,1]\n",
    "  \n",
    "# Make a column with the largest probability\n",
    "inference['goal_highest_prob'] = inference[[col for col in inference.columns if \"predicted_prob\" in col]].idxmax(1)\n",
    "inference['goal_highest_prob'] = inference['goal_highest_prob'].str.replace('_predicted_prob', '')\n",
    "inference['goal_highest_prob'] = inference['goal_highest_prob'].str.replace('goal_', '')\n",
    "\n",
    "# Save only columns of prediction results\n",
    "cols_to_drop = ['text', 'ad_creative_bodies', 'ad_snapshot_url',\n",
    "       'ad_creative_link_captions', 'ad_creative_link_titles',\n",
    "       'ad_creative_link_descriptions', 'checksum',]\n",
    "inference = inference.drop(cols_to_drop, axis=1)\n",
    "\n",
    "inference.to_csv(path_predictions_gz, index = False,\n",
    "                compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ede2f-371e-4b60-824a-ede12d0875b4",
   "metadata": {},
   "source": [
    "## Inference: Google 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2ed0d1f-9bb8-43c7-aea2-2774947b6213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [08:25<00:00, 168.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "path_google_2022 = 'data/google_2022_prepared.csv.gz'\n",
    "# dir_models = 'models/goal_rf_'\n",
    "\n",
    "# Ouput data\n",
    "path_predictions_gz = 'data/ad_goal_rf_google_2022.csv.gz'\n",
    "\n",
    "# Load data\n",
    "inference = pd.read_csv(path_google_2022)\n",
    "inference = inference[inference['text'] != \"\"]\n",
    "inference = inference.dropna(subset='text')\n",
    "\n",
    "goals = [\"PRIMARY_PERSUADE\", \"DONATE\", \"GOTV\"]\n",
    "\n",
    "for g in tqdm(goals):\n",
    "\n",
    "  # Load model\n",
    "  clf = models[g]\n",
    "    \n",
    "  # Load saved model\n",
    "  # clf = load(dir_models + g + '.joblib')\n",
    "  \n",
    "  # Apply clf\n",
    "  predicted_prob = clf.predict_proba(inference['text'])\n",
    "  predicted = np.argmax(predicted_prob, axis=1)\n",
    "  \n",
    "  inference['goal_'+g+'_prediction'] = predicted\n",
    "  inference['goal_'+g+'_predicted_prob'] = predicted_prob[:,1]\n",
    "\n",
    "\n",
    "# Make a column with the largest probability\n",
    "inference['goal_highest_prob'] = inference[[col for col in inference.columns if \"predicted_prob\" in col]].idxmax(1)\n",
    "inference['goal_highest_prob'] = inference['goal_highest_prob'].str.replace('_predicted_prob', '')\n",
    "inference['goal_highest_prob'] = inference['goal_highest_prob'].str.replace('goal_', '')\n",
    "\n",
    "# Save only columns of goal predictions\n",
    "cols_to_drop = ['wmp_creative_id', 'ad_type', 'csum_agg',\n",
    "       'advertiser_id', 'aws_face_vid', 'aws_face_img', 'impressions',\n",
    "       'age_targeting', 'gender_targeting', 'geo_targeting_included',\n",
    "       'geo_targeting_excluded', 'spend_range_min_usd', 'spend_range_max_usd',]\n",
    "\n",
    "inference = inference.drop(cols_to_drop, axis=1)\n",
    "\n",
    "inference.to_csv(path_predictions_gz, index = False,\n",
    "                compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c01f50-592d-4125-b3d2-3a3025a4cf65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
